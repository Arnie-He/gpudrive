mode: "train"
use_rnn: false
eval_model_path: null
baseline: false
data_dir: "data/processed/validation" #"data/formatted_json_v2_no_tl_valid" #"data/processed/examples" #"data/data_old_debug" #"data/data_old_debug" #"data/processed/training" # Dataset

environment: # Overrides default environment configs (see pygpudrive/env/config.py)
  name: "gpudrive"
  num_worlds: 100 # Number of parallel environments
  k_unique_scenes: 50 # Number of unique scenes to sample from
  max_controlled_agents: 32 # Maximum number of agents controlled by the model. Make sure this aligns with the variable kMaxAgentCount in src/consts.hpp
  ego_state: true
  road_map_obs: true
  partner_obs: true
  normalize_obs: true
  remove_non_vehicles: false
  use_lidar_obs: false # automatically turns of the other observation types
  reward_type: "weighted_combination"
  dynamics_model: "classic"
  collision_behavior: "remove"
  dist_to_goal_threshold: 5.0
  polyline_reduction_threshold: 0.01 # Rate at which to sample points from the polyline (0 is all, 1 maximum sparsity), needs to be balanced with kMaxAgentMapObservationsCount

wandb:
  entity: ""
  project: "gpudrive"
  group: "algorithm_logic"
  mode: "online" # Options: online, offline, disabled
  tags: ["ppo", "ff", "single_scene"]

## NOTES
## Set batch size to 128 * number of controlled agents (e.g. 2**18)
## Minibatch size 1/16 of batch size, eg. 16_000

train:
  exp_id: Puffer  # Set dynamically in the script if needed
  seed: 42
  cpu_offload: false
  device: "cuda"  # Dynamically set to cuda if available, else cpu
  torch_deterministic: false
  total_timesteps: 100_000_000
  batch_size: 32_768
  minibatch_size: 16_384
  learning_rate: 3e-4
  anneal_lr: false
  gamma: 0.99
  gae_lambda: 0.95
  update_epochs: 5
  norm_adv: true
  clip_coef: 0.2
  clip_vloss: false
  vf_clip_coef: 0.2
  ent_coef: 0.0001
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: null
  checkpoint_interval: 500 # Save policy every k iterations
  checkpoint_path: "./runs"
  bptt_horizon: 2
  compile: false
  compile_mode: "reduce-overhead"
  # Rendering configs
  render: false # Determines whether to render the environment
  render_interval: 100 # Render every k rollouts
  render_k_scenarios: 10 # Number of scenarios to render
  render_agent_obs: false # Debugging tool, plot what an agent is seing
  render_simulator_state: true # Plot the simulator state from bird's eye view
  render_fps: 20
  render_format: "mp4" # Options: gif, mp4

vec:
  backend: "native" # Only native is currently supported
  num_workers: 1
  env_batch_size: 1
  zero_copy: false
