{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows for multiple policies to be compared at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
>>>>>>> cb306b0 (finishing tutorial 8)
   "source": [
    "import torch\n",
    "import dataclasses\n",
    "import mediapy\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "from huggingface_hub import ModelCard\n",
    "from gpudrive.networks.late_fusion import NeuralNet\n",
    "from gpudrive.agents.core import merge_actions,create_policy_masks\n",
    "from gpudrive.env.config import EnvConfig\n",
    "from gpudrive.env.env_torch import GPUDriveTorchEnv\n",
    "from gpudrive.visualize.utils import img_from_fig\n",
    "from gpudrive.env.dataset import SceneDataLoader\n",
    "from gpudrive.utils.config import load_config \n",
    "import sys\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "sys.path.append(project_root+'/examples/experimental')\n",
    "\n",
    "from eval_utils import multi_policy_rollout,compute_metrics  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 23,
>>>>>>> cb306b0 (finishing tutorial 8)
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_policy_masks(env, num_sim_agents=2, num_worlds=10):\n",
    "    policy_mask = torch.zeros_like(env.cont_agent_mask, dtype=torch.int)\n",
    "    agent_indices = env.cont_agent_mask.nonzero(as_tuple=True)\n",
    "\n",
    "    for i, (world_idx, agent_idx) in enumerate(zip(*agent_indices)):\n",
    "        policy_mask[world_idx, agent_idx] = (i % num_sim_agents) + 1\n",
    "\n",
    "    policy_masks = {f'pi_{int(policy.item())}': torch.zeros_like(env.cont_agent_mask, dtype=torch.bool,device=device) \n",
    "                    for policy in policy_mask.unique() if policy.item() != 0}\n",
    "\n",
    "    for p in range(1, num_sim_agents + 1):\n",
    "        policy_masks[f'pi_{p}'] = (policy_mask == p).reshape(num_worlds, -1)\n",
    "\n",
    "    return policy_masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 24,
>>>>>>> cb306b0 (finishing tutorial 8)
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = load_config(project_root+\"/examples/experimental/config/eval_config\")\n",
    "\n",
    "VIDEO_PATH = \"videos\"\n",
    "\n",
    "max_agents = config.max_controlled_agents\n",
    "NUM_WORLDS = 2\n",
    "device = \"cpu\" # cpu just because we're in a notebook\n",
    "NUM_SIM_AGENTS = 2\n",
    "FPS = 5\n",
    "\n",
    "sim_agent1 = NeuralNet.from_pretrained(\"daphne-cornelisse/policy_S10_000_02_27\")\n",
    "sim_agent2 = NeuralNet.from_pretrained(\"daphne-cornelisse/policy_S1000_02_27\")\n",
    "\n",
    "# Some other info\n",
    "card = ModelCard.load(\"daphne-cornelisse/policy_S10_000_02_27\")\n",
    "\n",
    "\n",
    "VIDEO_PATH = \"videos\"\n",
    "\n",
    "max_agents = config.max_controlled_agents\n",
    "NUM_WORLDS = 2\n",
    "device = \"cpu\" # cpu just because we're in a notebook\n",
    "NUM_SIM_AGENTS = 2\n",
    "FPS = 5\n",
    "\n",
    "sim_agent1 = NeuralNet.from_pretrained(\"daphne-cornelisse/policy_S10_000_02_27\")\n",
    "sim_agent2 = NeuralNet.from_pretrained(\"daphne-cornelisse/policy_S1000_02_27\")\n",
    "\n",
    "# Some other info\n",
    "card = ModelCard.load(\"daphne-cornelisse/policy_S10_000_02_27\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 26,
>>>>>>> cb306b0 (finishing tutorial 8)
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/charliemolony/Desktop/gpudrive/data/processed/examples\n",
    "# Create data loader\n",
    "train_loader = SceneDataLoader(\n",
    "    root=project_root+'/data/processed/examples',\n",
    "    batch_size=NUM_WORLDS,\n",
    "    dataset_size=100,\n",
    "    sample_with_replacement=False,\n",
    ")\n",
    "\n",
    "# Set params\n",
    "env_config = dataclasses.replace(\n",
    "    EnvConfig(),\n",
    "    ego_state=config.ego_state,\n",
    "    road_map_obs=config.road_map_obs,\n",
    "    partner_obs=config.partner_obs,\n",
    "    reward_type=config.reward_type,\n",
    "    norm_obs=config.norm_obs,\n",
    "    dynamics_model=config.dynamics_model,\n",
    "    collision_behavior=config.collision_behavior,\n",
    "    dist_to_goal_threshold=config.dist_to_goal_threshold,\n",
    "    polyline_reduction_threshold=config.polyline_reduction_threshold,\n",
    "    remove_non_vehicles=config.remove_non_vehicles,\n",
    "    lidar_obs=config.lidar_obs,\n",
    "    disable_classic_obs=config.lidar_obs,\n",
    "    obs_radius=config.obs_radius,\n",
    "    steer_actions = torch.round(\n",
    "        torch.linspace(-torch.pi, torch.pi, config.action_space_steer_disc), decimals=3  \n",
    "    ),\n",
    "    accel_actions = torch.round(\n",
    "        torch.linspace(-4.0, 4.0, config.action_space_accel_disc), decimals=3\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "env = GPUDriveTorchEnv(\n",
    "    config=env_config,\n",
    "    data_loader=train_loader,\n",
    "    max_cont_agents=config.max_controlled_agents,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "t: 1\n",
      "t: 2\n",
      "t: 3\n",
      "t: 4\n",
      "t: 5\n",
      "t: 6\n",
      "t: 7\n",
      "t: 8\n",
      "t: 9\n",
      "t: 10\n",
      "t: 11\n",
      "t: 12\n",
      "t: 13\n",
      "t: 14\n",
      "t: 15\n",
      "t: 16\n",
      "t: 17\n",
      "t: 18\n",
      "t: 19\n",
      "t: 20\n",
      "t: 21\n",
      "t: 22\n",
      "t: 23\n",
      "t: 24\n",
      "t: 25\n",
      "t: 26\n",
      "t: 27\n",
      "t: 28\n",
      "t: 29\n",
      "t: 30\n",
      "t: 31\n",
      "t: 32\n",
      "t: 33\n",
      "t: 34\n",
      "t: 35\n",
      "t: 36\n",
      "t: 37\n",
      "t: 38\n",
      "t: 39\n",
      "t: 40\n",
      "t: 41\n",
      "t: 42\n",
      "t: 43\n",
      "t: 44\n",
      "t: 45\n",
      "t: 46\n",
      "t: 47\n",
      "t: 48\n",
      "t: 49\n",
      "t: 50\n",
      "t: 51\n",
      "t: 52\n",
      "t: 53\n",
      "t: 54\n"
     ]
    }
   ],
>>>>>>> cb306b0 (finishing tutorial 8)
   "source": [
    "next_obs = env.reset()\n",
    "\n",
    "\n",
    "control_mask = env.cont_agent_mask\n",
    "\n",
    "policy_mask = create_policy_masks(env, 2,NUM_WORLDS)\n",
    "\n",
    "policies_set = {'pi_1': (sim_agent1,policy_mask['pi_1']),\n",
    "                'pi_2': (sim_agent2, policy_mask['pi_2'])\n",
    "                } \n",
    "        \n",
    "\n",
    "\n",
    "metrics,frames=multi_policy_rollout(\n",
    "env,\n",
    "policies_set, \n",
    "device,\n",
    "deterministic=False,\n",
    "render_sim_state = True,\n",
    "render_every_n_steps= 5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m scene_name, frames_list \u001b[38;5;129;01min\u001b[39;00m frames.items():\n\u001b[32m      2\u001b[39m     frames_arr = np.array(frames_list)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mmediapy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgif\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gpudriveenv/lib/python3.11/site-packages/mediapy/__init__.py:1942\u001b[39m, in \u001b[36mshow_videos\u001b[39m\u001b[34m(videos, titles, width, height, downsample, columns, fps, bps, qp, codec, ylabel, html_class, return_html, **kwargs)\u001b[39m\n\u001b[32m   1939\u001b[39m w, h = _get_width_height(width, height, first_image.shape[:\u001b[32m2\u001b[39m])\n\u001b[32m   1940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m downsample \u001b[38;5;129;01mand\u001b[39;00m (w < first_image.shape[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m h < first_image.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m   1941\u001b[39m   \u001b[38;5;66;03m# Not resize_video() because each image may have different depth and type.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1942\u001b[39m   video = \u001b[43m[\u001b[49m\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1943\u001b[39m   first_image = video[\u001b[32m0\u001b[39m]\n\u001b[32m   1944\u001b[39m data = compress_video(\n\u001b[32m   1945\u001b[39m     video, metadata=metadata, fps=fps, bps=bps, qp=qp, codec=codec\n\u001b[32m   1946\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gpudriveenv/lib/python3.11/site-packages/mediapy/__init__.py:1942\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1939\u001b[39m w, h = _get_width_height(width, height, first_image.shape[:\u001b[32m2\u001b[39m])\n\u001b[32m   1940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m downsample \u001b[38;5;129;01mand\u001b[39;00m (w < first_image.shape[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m h < first_image.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m   1941\u001b[39m   \u001b[38;5;66;03m# Not resize_video() because each image may have different depth and type.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1942\u001b[39m   video = [\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m video]\n\u001b[32m   1943\u001b[39m   first_image = video[\u001b[32m0\u001b[39m]\n\u001b[32m   1944\u001b[39m data = compress_video(\n\u001b[32m   1945\u001b[39m     video, metadata=metadata, fps=fps, bps=bps, qp=qp, codec=codec\n\u001b[32m   1946\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gpudriveenv/lib/python3.11/site-packages/mediapy/__init__.py:638\u001b[39m, in \u001b[36mresize_image\u001b[39m\u001b[34m(image, shape)\u001b[39m\n\u001b[32m    633\u001b[39m supported_multichannel = (\n\u001b[32m    634\u001b[39m     image.dtype == np.uint8 \u001b[38;5;129;01mand\u001b[39;00m image.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m image.shape[\u001b[32m2\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m)\n\u001b[32m    635\u001b[39m )\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m supported_single_channel \u001b[38;5;129;01mor\u001b[39;00m supported_multichannel:\n\u001b[32m    637\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m np.array(\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m       \u001b[43m_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m          \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPIL\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResampling\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLANCZOS\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    641\u001b[39m       dtype=image.dtype,\n\u001b[32m    642\u001b[39m   )\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m    644\u001b[39m   \u001b[38;5;66;03m# We convert to floating-point for resizing and convert back.\u001b[39;00m\n\u001b[32m    645\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m to_type(resize_image(to_float01(image), shape), image.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gpudriveenv/lib/python3.11/site-packages/PIL/Image.py:2356\u001b[39m, in \u001b[36mImage.resize\u001b[39m\u001b[34m(self, size, resample, box, reducing_gap)\u001b[39m\n\u001b[32m   2344\u001b[39m         \u001b[38;5;28mself\u001b[39m = (\n\u001b[32m   2345\u001b[39m             \u001b[38;5;28mself\u001b[39m.reduce(factor, box=reduce_box)\n\u001b[32m   2346\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.reduce)\n\u001b[32m   2347\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m Image.reduce(\u001b[38;5;28mself\u001b[39m, factor, box=reduce_box)\n\u001b[32m   2348\u001b[39m         )\n\u001b[32m   2349\u001b[39m         box = (\n\u001b[32m   2350\u001b[39m             (box[\u001b[32m0\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2351\u001b[39m             (box[\u001b[32m1\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2352\u001b[39m             (box[\u001b[32m2\u001b[39m] - reduce_box[\u001b[32m0\u001b[39m]) / factor_x,\n\u001b[32m   2353\u001b[39m             (box[\u001b[32m3\u001b[39m] - reduce_box[\u001b[32m1\u001b[39m]) / factor_y,\n\u001b[32m   2354\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
>>>>>>> cb306b0 (finishing tutorial 8)
   "source": [
    "\n",
    "for scene_name, frames_list in frames.items():\n",
    "    frames_arr = np.array(frames_list)\n",
    "    mediapy.show_videos(frames_arr, fps=15, width=500, height=500, columns=2, codec='gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpudriveenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
