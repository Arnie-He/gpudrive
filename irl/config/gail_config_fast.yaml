# GAIL Configuration - Optimized for Fast Training
# Smaller batch sizes for reasonable inner loop times

mode: "train"
use_rnn: false
eval_model_path: null
baseline: false
data_dir: data/processed/training
continue_training: false
model_cpt: null

environment:
  name: "gpudrive"
  num_worlds: 64  # Reduced for faster training
  k_unique_scenes: 64
  max_controlled_agents: 2 # Maximum number of agents controlled by the model. Make sure this aligns with the variable kMaxAgentCount in src/consts.hpp
  ego_state: true
  road_map_obs: true
  partner_obs: true
  norm_obs: true
  remove_non_vehicles: true
  lidar_obs: false
  reward_type: "weighted_combination"
  collision_weight: -0.75
  off_road_weight: -0.75
  goal_achieved_weight: 1.0
  dynamics_model: "classic"
  collision_behavior: "ignore"
  dist_to_goal_threshold: 2.0
  polyline_reduction_threshold: 0.1
  sampling_seed: 42
  obs_radius: 50.0
  action_space_steer_disc: 13
  action_space_accel_disc: 7
  use_vbd: false
  vbd_model_path: "gpudrive/integrations/vbd/weights/epoch=18.ckpt"
  init_steps: 11
  vbd_trajectory_weight: 0.1
  vbd_in_obs: false

wandb:
  entity: "rl-power"
  project: "gpudrive"
  group: "fast-gail"
  mode: "online"
  tags: ["gail", "fast"]

train:
  # General training parameters
  exp_id: "gail_fast"
  seed: 42
  cpu_offload: false
  device: "cuda"
  bptt_horizon: 1
  compile: false
  compile_mode: "reduce-overhead"

  # Data sampling
  resample_scenes: false
  resample_dataset_size: 10_000
  resample_interval: 2_000_000
  sample_with_replacement: true
  shuffle_dataset: false

  # PPO - OPTIMIZED FOR GAIL
  torch_deterministic: false
  total_timesteps: 10_000_000
  batch_size: 16384        # 8x smaller than original (131072 -> 16384)
  minibatch_size: 2048     # 4x smaller than original (8192 -> 2048)
  learning_rate: 3e-4
  anneal_lr: false
  gamma: 0.99
  gae_lambda: 0.95
  update_epochs: 3         # Reduced from 4 to 3 for speed
  norm_adv: true
  clip_coef: 0.2
  clip_vloss: false
  vf_clip_coef: 0.2
  ent_coef: 0.001         # Slightly increased for exploration
  vf_coef: 0.3
  max_grad_norm: 0.5
  target_kl: null
  log_window: 1000
  
  # L2 Regularization
  policy_weight_decay: 1e-4        # L2 regularization for policy network
  value_weight_decay: 1e-4         # L2 regularization for value network
  
  # GAIL - OPTIMIZED FOR SPEED
  use_gail: true
  discriminator_lr: 1e-3               # Slightly higher for faster learning
  discriminator_hidden_dim: 128        # Smaller network for speed
  discriminator_dropout: 0.1
  discriminator_batch_size: 512        # Smaller batches for speed
  discriminator_epochs: 3              # Reduced from 5 to 3
  discriminator_update_freq: 1         # Update every policy update
  policy_buffer_size: 20000            # Smaller buffer for memory efficiency
  min_policy_data: 512                 # Lower threshold to start training
  discriminator_weight_decay: 1e-4     # L2 regularization for discriminator
  
  # Network architecture
  network:
    input_dim: 64
    hidden_dim: 128
    dropout: 0.01
    class_name: "NeuralNet"
    num_parameters: 0
  
  # Checkpointing
  checkpoint_interval: 400
  checkpoint_path: "./runs"

  # Rendering
  render: false
  render_3d: true
  render_interval: 1
  render_k_scenarios: 10
  render_format: "mp4"
  render_fps: 15
  zoom_radius: 50

vec:
  num_envs: 1
  async_: true 